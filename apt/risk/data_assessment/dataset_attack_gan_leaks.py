"""
This module implements privacy risk assessment of synthetic datasets based on the paper:
"GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models" by D. Chen, N. Yu, Y. Zhang, M. Fritz
published in Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, 343â€“62, 2020.
https://doi.org/10.1145/3372297.3417238 and its implementation in https://github.com/DingfanChen/GAN-Leaks.
"""
from dataclasses import dataclass
from typing import Optional

import numpy as np
from sklearn.neighbors import NearestNeighbors

from apt.risk.data_assessment.attack_strategy_utils import KNNAttackStrategyUtils
from apt.risk.data_assessment.dataset_attack import DatasetAttackPerRecord, Config
from apt.risk.data_assessment.dataset_attack_result import DatasetAttackScore, DatasetAttackResultPerRecord
from apt.utils.datasets import ArrayDataset


@dataclass
class DatasetAttackGanLeaksConfig(Config):
    """Configuration for DatasetAttackGanLeaks.

    Attributes:
        k: Number of nearest neighbors to search
        use_batches: Divide query samples into batches or not.
        batch_size:  Query sample batch size.
        compute_distance: A callable function, which takes two arrays representing 1D vectors as inputs and must return
            one value indicating the distance between those vectors. See sklearn.neighbors.NearestNeighbors documentation.
        batch_size:  Additional keyword arguments for the distance computation function.
    """
    k: int = 1
    use_batches: bool = False
    batch_size: int = 10
    compute_distance: callable = None
    distance_params: dict = None


@dataclass
class DatasetAttackScoreGanLeaks(DatasetAttackScore):
    """Configuration for DatasetAttackGanLeaks.
    Attributes
    ----------
    roc_auc_score : the share of synthetic records closer to the training than the holdout dataset
    average_precision_score:
    assessment_type : assessment type is 'GANLeaks', to be used in reports
    """
    roc_auc_score: float
    average_precision_score: float
    assessment_type: str = 'GANLeaks'


class DatasetAttackGanLeaks(DatasetAttackPerRecord):
    """
         Privacy risk assessment for synthetic datasets based Black-Box MIA attack using distances of
         members (training set) and non-members (holdout set) from their nearest neighbors in the synthetic dataset.
         The area under the receiver operating characteristic curve (AUCROC) gives the privacy risk measure.
    """

    def __init__(self, original_data_members: ArrayDataset, original_data_non_members: ArrayDataset,
                 synthetic_data: ArrayDataset, dataset_name: str,
                 config: Optional[DatasetAttackGanLeaksConfig] = DatasetAttackGanLeaksConfig()):
        """
        :param original_data_members: A container for the training original samples and labels
        :param original_data_non_members: A container for the holdout original samples and labels
        :param synthetic_data: A container for the synthetic samples and labels
        :param dataset_name: A name to identify this dataset
        :param config: Configuration parameters to guide the assessment process such as which attack
               frameworks to use, optional
        """
        attack_strategy_utils = KNNAttackStrategyUtils(config.k, config.use_batches, config.batch_size)
        super().__init__(original_data_members, original_data_non_members, synthetic_data, dataset_name,
                         attack_strategy_utils, config)
        if config.compute_distance:
            self.nn_obj = NearestNeighbors(n_neighbors=config.k, algorithm='auto', metric=config.compute_distance,
                                           metric_params=config.distance_params)
        else:
            self.nn_obj = NearestNeighbors(n_neighbors=config.k, algorithm='auto')

    def assess_privacy(self) -> DatasetAttackResultPerRecord:
        """
        Calculate probabilities of positive and negative samples to be generated by the synthetic data generator
        :return:
            :result of the attack, based on the NN distances from the query samples to the synthetic data samples
        """
        # nearest neighbor search
        self.attack_strategy_utils.fit(self.synthetic_data, self.nn_obj)

        # positive query
        pos_proba = self.attack_strategy_utils.find_knn(self.original_data_members, self.nn_obj,
                                                        self.probability_per_sample)

        # negative query
        neg_proba = self.attack_strategy_utils.find_knn(self.original_data_non_members, self.nn_obj,
                                                        self.probability_per_sample)

        result = DatasetAttackResultPerRecord(self.dataset_name, positive_probabilities=pos_proba,
                                              negative_probabilities=neg_proba)
        return result

    def calculate_privacy_score(self, dataset_attack_result: DatasetAttackResultPerRecord,
                                generate_plot=False) -> DatasetAttackScore:
        """
        Calculate probabilities of positive and negative samples to be generated by the synthetic data generator
        :param dataset_attack_result attack result containing probabilities of positive and negative samples to be
                generated by the synthetic data generator
        :param generate_plot generate AUC ROC curve plot and persist it
        :return:
            :score of the attack, based on distance-based probabilities
        """
        pos_proba, neg_proba = \
            dataset_attack_result.positive_probabilities, dataset_attack_result.negative_probabilities
        fpr, tpr, threshold, auc, ap = self.calculate_roc_score(pos_proba, neg_proba)
        score = DatasetAttackScoreGanLeaks(self.dataset_name, roc_auc_score=auc, average_precision_score=ap)
        if generate_plot:
            self.plot_roc_curve(pos_proba, neg_proba)
        return score

    @staticmethod
    def probability_per_sample(distances: np.ndarray):
        """
        For every sample represented by its distance from the query sample to its KNN in synthetic data,
        the probability of the synthetic data to be part of the query dataset.
        :param distances: distance between every query sample in batch to its KNNs among synthetic samples
        :return:
            distances: probability estimates of the query samples being generated and so being part of the synthetic set
        """
        return np.average(np.exp(-distances), axis=1)
